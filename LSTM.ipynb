{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import xarray\n",
    "import cftime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:         (bounds: 2, month: 12, time: 7800)\n",
      "Coordinates:\n",
      "  * time            (time) float64 15.5 45.0 74.5 ... 2.372e+05 2.372e+05\n",
      "Dimensions without coordinates: bounds, month\n",
      "Data variables:\n",
      "    nino34          (time) float64 ...\n",
      "    time_bnds       (time, bounds) float64 ...\n",
      "    areacello       float32 ...\n",
      "    days_per_month  (month) int32 ...\n"
     ]
    }
   ],
   "source": [
    "datapath = 'nino34_monthly.nc'\n",
    "nino34 = xarray.open_dataset(datapath, decode_times = False)\n",
    "print(nino34)\n",
    "nino34 = np.array(nino34['nino34'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ONI(nino34, m = 3):\n",
    "    oni = np.array(nino34)\n",
    "    length = nino34.shape[0]\n",
    "    for i in range(length):\n",
    "        oni[i] = np.mean(nino34[max(0, (i - m + 1)) : min((i + 1), length)])\n",
    "    return oni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "oni = ONI(nino34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def climatology(nino34):\n",
    "    clm = np.zeros(12)\n",
    "    length = nino34.shape[0]\n",
    "    for month in range(12):\n",
    "        section = [12 * i + month for i in range(length // 12)]\n",
    "        clm[month] = np.mean(nino34[section])\n",
    "    return clm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "clm = climatology(nino34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SST_anomaly(nino34, clm):\n",
    "    anm = np.array(nino34)\n",
    "    length = nino34.shape[0]\n",
    "    for i in range(length):\n",
    "        anm[i] = nino34[i] - clm[i % 12]\n",
    "    return anm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "anm = SST_anomaly(nino34, clm)\n",
    "oanm = ONI(anm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 7      # prediction timeline\n",
    "H = 32   # history used for prediction\n",
    "include_month = 1           # 1 if we use the month as a feature, 0 otherwise\n",
    "threshold = 0.5         \n",
    "signal = np.array(nino34[12 * 50:])   # data used for training/testing\n",
    "length = signal.shape[0]    # number of data points\n",
    "\n",
    "mean = np.mean(signal)\n",
    "std = np.std(signal)\n",
    "\n",
    "signal = (signal - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 7000\n",
    "sample_len = 350\n",
    "n_samples = size // sample_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "        \n",
    "# create the 'history matrix'\n",
    "data = np.ndarray((n_samples, sample_len, H + include_month))\n",
    "for i in range(n_samples):\n",
    "    for j in range(sample_len):\n",
    "        t = sample_len * i + j\n",
    "        if(include_month == False):\n",
    "             data[i,j] = signal[t:(t + H)]\n",
    "        else:\n",
    "            data[i,j] = np.append(signal[t:(t + H)], (t + H + T) % 12 / 12)\n",
    "\n",
    "labels = np.ndarray((n_samples, sample_len), dtype = int)\n",
    "        \n",
    "for i in range(n_samples):\n",
    "    for j in range(sample_len):\n",
    "        t = sample_len * i + j\n",
    "        labels[i, j] = oanm[t + H + T]\n",
    "\n",
    "split = n_samples // 10      \n",
    "shuffle = np.random.permutation(n_samples)\n",
    "train_ind = np.array(shuffle[0: 8 * split])\n",
    "val_ind = np.array(shuffle[8 * split: 9 * split])\n",
    "test_ind = np.array(shuffle[9 * split: size])\n",
    "\n",
    "train = np.array(data[train_ind])\n",
    "train_labels = np.array(labels[train_ind])\n",
    "\n",
    "val = np.array(data[val_ind])\n",
    "val_labels = np.array(labels[val_ind])\n",
    "\n",
    "test = np.array(data[test_ind])\n",
    "test_labels = np.array(labels[test_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 mse : 0.4439932703971863 0.4565284252166748\n",
      "10 mae : 0.28593870997428894 0.3852995038032532\n",
      "20 mse : 0.2769436836242676 0.3629114627838135\n",
      "20 mae : 0.2807210683822632 0.3219720125198364\n",
      "30 mse : 0.34416961669921875 0.38427823781967163\n",
      "30 mae : 0.32868683338165283 0.31550246477127075\n",
      "40 mse : 0.3221272826194763 0.36283326148986816\n",
      "40 mae : 0.27166908979415894 0.3132445216178894\n",
      "50 mse : 0.32102036476135254 0.30800414085388184\n",
      "50 mae : 0.357069194316864 0.3703349828720093\n",
      "60 mse : 0.3003605604171753 0.34306246042251587\n",
      "60 mae : 0.3151930570602417 0.2767164707183838\n",
      "70 mse : 0.271484375 0.32294368743896484\n",
      "70 mae : 0.28286606073379517 0.31111547350883484\n",
      "80 mse : 0.30231577157974243 0.31452441215515137\n",
      "80 mae : 0.3346917927265167 0.3304855227470398\n",
      "90 mse : 0.34859979152679443 0.3579505681991577\n",
      "90 mae : 0.3212650418281555 0.287781298160553\n"
     ]
    }
   ],
   "source": [
    "(d, N1, N2, N3) = (0.3, 768, 768, 384)\n",
    "epochs = 100\n",
    "        \n",
    "acc = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for n_neurons in range(10, 100, 10):\n",
    "    for l in ['mse', 'mae']:\n",
    "\n",
    "        model = tf.keras.models.Sequential([\n",
    "                  tf.keras.layers.LSTM(n_neurons),\n",
    "                  tf.keras.layers.Dense(1)\n",
    "                ])\n",
    "\n",
    "        model.reset_states()\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                loss = l,\n",
    "                metrics=['mse', 'mae'])\n",
    "\n",
    "        model.fit(train, train_labels, batch_size=n_samples, epochs = epochs, verbose = 0)\n",
    "        (loss, mse, mae) = model.evaluate(val, val_labels, verbose = 0)\n",
    "\n",
    "        print(n_neurons, l, \":\", mse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
